
## ICASSP2023

### Time-Variance Aware Real-Time Speech Enhancement

#### abs & intro
语音信号在实时通信中经常受到干扰，从而降低了语音质量和用户体验。发送端的环境噪声和声学回声是影响近端语音质量的主要干扰因素。回声是由于实时通信系统中扬声器和麦克风的耦合造成的，以致远端用户听到自己的声音的延迟和修改版本。因此，语音增强，包括深度降噪（DNS）和声学回声消除（AEC），旨在去除回声和环境噪声，只传递近端语音到远端。实时全双工通信应用中经常出现时变因素。用户移动或环境变化可能导致声学路径和非平稳噪声的变化。前端信号传输和预处理模块常常导致麦克风和远端信号之间的逐帧不对齐。这可能导致双信号之间的时间延迟随着音频帧的变化而变化，我们将其称为“动态延迟”。在传统的语音增强算法中，这些时变分量通过自适应方式动态跟踪输入信号来捕获。

最近的研究将语音增强视为时间序列回归问题，并使用深度神经网络（DNN）进行非线性建模，可以分为DSP-DNN混合方法和端到端DNN方法。在混合方法中，DSP模块显式捕获时变性并部分抑制回声和噪声，而DNN模块作为后处理器来消除剩余的干扰。在端到端方法中，DNN也可以隐式地建模时变分量。受这两种方法的启发，为DNN增加显式的时变性意识和建模能力，可以在处理时变信号方面增强其性能，特别是在端到端的方式下。

在本文中，我们提出了一种动态核生成（DKG）模块，用于明确建模实时语音增强中的时变性。这个DKG模块可以作为一个可学习的插件引入，并通过DNN的端到端优化进行训练。具体而言，对于每个输入的音频帧，DKG模块生成一个卷积核，并将其应用于当前和历史音频帧的特征，然后使用重新校准的特征获得相应的输出音频帧。这使得DNN模型能够根据时变输入在推断过程中动态调整其权重。我们引入了两种不同结构的DKG，即可分离和不可分离的DKG，用于不同实现的时变成分捕获。通过对合成数据集进行的消融研究表明，所提出的DKG模块在时变场景下，特别是在变化的声学路径和动态延迟的情况下，改善了模型的性能。在真实世界数据集上的实验结果也验证了所提出模块的有效性

#### Methods
  
A. 问题描述 在传统的声学信号模型中，麦克风信号 y(t) 是近端信号 s(t)、回声 d(t) 和背景噪声 n(t) 的混合物：y(t) = d(t) + s(t) + n(t)。 (1) 回声信号 d(t) 是从远端信号生成的，首先通过非线性组件（例如功率放大器和扬声器）扭曲，然后与房间冲激响应（RIR）卷积。联合的声学回声消除（AEC）和深度降噪（DNS）问题是从麦克风信号中估计干净的近端信号

B. 总体架构 图1展示了带有提出的动态内核生成（DKG）模块的联合模型的总体架构。该模型由两个独立的编码器、一个解码器和若干个连接在它们之间的重复的时变性感知语音增强（TVASE）模块组成。模型接受麦克风的短时傅里叶变换（STFT）频谱 Y ∈ R2×T ×F 和远端信号 X ∈ R2×T ×F 作为输入，并估计近端信号的STFT频谱，其中 T 是帧数，F 是频率频带数，每个复数频谱都有实部和虚部。麦克风和远端频谱分别输入两个独立的编码器。每个编码器包含四个2-D因果卷积层 [16]，逐渐沿着频率维度对特征进行下采样，并增加其通道数。从两个编码器输出的特征进行连接，然后通过一个2-D因果卷积层，将频率维度合并到通道维度，得到形状为 R(F ′C)×T 的最终编码器特征。TVASE模块包含在[17]中定义的时域卷积模块（TCM）、自注意力模块和DKG模块，如图1中的虚线框所示。将TCM和自注意力模块结合在一起，旨在同时捕捉沿时域维度的局部和全局依赖关系，而DKG模块专注于明确建模输入特征的时变分量。
受多头自注意力设计的启发，多头自注意力从特征的不同子空间中提取信息[18]，我们将TCM的特征 FR ∈ R(F ′C)×T 分割为 I 组，得到 {Fi = FR[iC′ : (i + 1)C′, :], i ∈ {0, ..., I − 1}, C′ = F ′C I }。在每组上进行缩放点积自注意力计算。所有组的特征 F SA i 沿通道维度连接，然后通过卷积层以获得特征 F SA ∈ R(F ′C)×T 。在自注意力内部应用窗口掩码，窗口大小为 Tw，以保持其因果性：Fk i = (Convk i (Fi))tr，其中 k ∈ {K, Q, V }，F SA i = (Softmax(Mask(F Q i · (F K i )tr/ √ C′)) · F V i )tr，M ask(x)(i, j) = { x(i, j), 0 ≤ i − j ≤ T − Tw −∞，其中，Fi ∈ RC′×T，F k i ∈ RT ×C′ 和 F SA i ∈ RC′×T，分别表示不同维度的特征。上标 tr 表示对张量的最后两个维度进行转置。Convk i 代表一个1维卷积层，其后跟批归一化（BN）[19]和参数化ReLU（PReLU）[20]。解码器由四个类似于[21]的门控块组成，但采用因果卷积，最后还有一个额外的2D因果卷积层。除解码器中的最后一层外，所有卷积层后面都跟着BN和PReLU。C. DKG模块 为了更好地捕捉包括变化的声学路径和动态延迟在内的时变成分，我们引入了DKG模块，使模型能够在推理阶段根据输入信号自适应调整权重。给定输入特征 F SA ∈ R(F ′C)×T 和卷积核大小 M，DKG模块根据输入特征生成卷积核 K ∈ R(F ′C)×T ×M。然后对于单个特征帧 F SA(c, t) 的每个通道，应用卷积核 K(c, t) ∈ RM，得到相应的输出：F O(c, t) = t ∑ t′ =t−t0 K(c, t, t′ − (t − t0))F SA(c, t′)，其中 t0 = M −1，c ∈ {0, ..., F ′C −1}，t ∈ {0, ..., T −1}。基于是否在时间和通道维度上分别生成信息权重，我们提出了两种DKG模块的结构，即非可分和可分的DKG。非可分DKG模块如图2a所示。在这个结构中，直接使用单一映射生成卷积核：R(F ′C)×T 7→ R(F ′C)×T ×M。为了降低复杂性，我们将输入特征 F SA 分成 F ′ 组 {F SA i = F SA[iC : (i + 1)C, :]}，i ∈ {0, ..., F ′ − 1}，F SA i∈ RC×T。对于每个特征组，使用1维卷积层生成卷积核 KSA i (m)：RC 7→ RC×1×M。  
然后，所有的卷积核组在通道维度上进行连接，得到卷积核 K。可分DKG如图2b所示。在这个结构中，卷积核是使用两个独立的映射生成的，其中一个用于生成通道共享的滤波器 K0，另一个用于生成通道相关的权重 Ks，然后将Ks逐元素地与K0相乘。对于每个音频帧，通道共享的滤波器使用三个1维卷积层生成：RF ′C 7→ R1×1×M，通道相关的权重使用1维卷积层生成：RF ′C 7→ R(F ′C)×1×1。